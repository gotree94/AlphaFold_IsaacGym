# Alpamayo-R1 Inference ë…¸íŠ¸ë¶ ì½”ë“œ í•´ì„

## ê°œìš”

ì´ ë¬¸ì„œëŠ” **Alpamayo-R1** ììœ¨ì£¼í–‰ AI ëª¨ë¸ì˜ ì¶”ë¡ (inference) ë…¸íŠ¸ë¶ ì½”ë“œë¥¼ í•´ì„í•©ë‹ˆë‹¤.

Alpamayo-R1ì€ NVIDIAì—ì„œ ê°œë°œí•œ **VLA (Vision-Language-Action) ëª¨ë¸**ë¡œ, ì¹´ë©”ë¼ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì°¨ëŸ‰ì˜ ì£¼í–‰ ê²½ë¡œë¥¼ ì˜ˆì¸¡í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ìì—°ì–´ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ì „ì²´ íë¦„

```
ì…ë ¥ ì´ë¯¸ì§€ â†’ ëª¨ë¸ ì¶”ë¡  â†’ ê²½ë¡œ ì˜ˆì¸¡ + ì´ìœ  ì„¤ëª… â†’ ì‹œê°í™” â†’ ì •í™•ë„ í‰ê°€
```

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Alpamayo-R1 ì¶”ë¡  ê³¼ì •                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. ì…ë ¥                                                    â”‚
â”‚     - ì¹´ë©”ë¼ ì´ë¯¸ì§€ (ì „ë°©/ì¸¡ë©´)                              â”‚
â”‚     - ì°¨ëŸ‰ ê³¼ê±° ìœ„ì¹˜/ë°©í–¥ ì´ë ¥                               â”‚
â”‚                                                             â”‚
â”‚  2. ëª¨ë¸ ì¶”ë¡  (VLA - Vision Language Action)                â”‚
â”‚     - ì´ë¯¸ì§€ ë¶„ì„ â†’ ìƒí™© ì´í•´                               â”‚
â”‚     - ì–¸ì–´ë¡œ ì´ìœ  ìƒì„± (Chain-of-Causation)                 â”‚
â”‚     - ë¯¸ë˜ ê²½ë¡œ ì˜ˆì¸¡                                        â”‚
â”‚                                                             â”‚
â”‚  3. ì¶œë ¥                                                    â”‚
â”‚     - pred_xyz: ì˜ˆì¸¡ ê²½ë¡œ ì¢Œí‘œ                              â”‚
â”‚     - CoC: "ê³µì‚¬ ì½˜ í”¼í•´ì„œ ì™¼ìª½ìœ¼ë¡œ ì´ë™"                    â”‚
â”‚     - minADE: 0.76m ì˜¤ì°¨                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì…€ë³„ ì½”ë“œ í•´ì„

### 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ Import

```python
import sys
sys.path.insert(0, '/home/gotree94/projects/alpamayo/repo/src')

import copy
import numpy as np
import mediapy as mp          # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì‹œê°í™”
import pandas as pd
import torch
from alpamayo_r1.models.alpamayo_r1 import AlpamayoR1  # ë©”ì¸ ëª¨ë¸
from alpamayo_r1.load_physical_aiavdataset import load_physical_aiavdataset  # ë°ì´í„° ë¡œë”
from alpamayo_r1 import helper  # ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
```

| ë¼ì´ë¸ŒëŸ¬ë¦¬ | ìš©ë„ |
|-----------|------|
| `numpy` | ìˆ˜ì¹˜ ì—°ì‚° |
| `mediapy` | ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì‹œê°í™” |
| `pandas` | ë°ì´í„° ì²˜ë¦¬ |
| `torch` | ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ |
| `AlpamayoR1` | Alpamayo-R1 ëª¨ë¸ í´ë˜ìŠ¤ |
| `load_physical_aiavdataset` | NVIDIA Physical AI AV ë°ì´í„°ì…‹ ë¡œë” |
| `helper` | ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ |

---

### 2. ëª¨ë¸ ë¡œë“œ

```python
model = AlpamayoR1.from_pretrained("nvidia/Alpamayo-R1-10B", dtype=torch.bfloat16).to("cuda")
processor = helper.get_processor(model.tokenizer)
```

| í•­ëª© | ì„¤ëª… |
|------|------|
| `nvidia/Alpamayo-R1-10B` | HuggingFaceì—ì„œ 100ì–µ íŒŒë¼ë¯¸í„° VLA ëª¨ë¸ ë‹¤ìš´ë¡œë“œ |
| `torch.bfloat16` | ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ 16ë¹„íŠ¸ ë¶€ë™ì†Œìˆ˜ì  |
| `.to("cuda")` | GPUë¡œ ëª¨ë¸ ì´ë™ |
| `processor` | ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ê¸° |

---

### 3. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬

```python
# í´ë¦½ ID ëª©ë¡ì—ì„œ íŠ¹ì • ì£¼í–‰ ì˜ìƒ ì„ íƒ
clip_ids = pd.read_parquet("clip_ids.parquet")["clip_id"].tolist()
clip_id = clip_ids[774]

# ë°ì´í„°ì…‹ì—ì„œ í•´ë‹¹ í´ë¦½ ë¡œë“œ
data = load_physical_aiavdataset(clip_id)

# ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ ì…ë ¥ ë©”ì‹œì§€ í¬ë§·ìœ¼ë¡œ ë³€í™˜
messages = helper.create_message(data["image_frames"].flatten(0, 1))

# í† í°í™” ë° ì „ì²˜ë¦¬
inputs = processor.apply_chat_template(
    messages,
    tokenize=True,
    add_generation_prompt=False,
    continue_final_message=True,
    return_dict=True,
    return_tensors="pt",
)

print("seq length:", inputs.input_ids.shape)

# ëª¨ë¸ ì…ë ¥ êµ¬ì„±
model_inputs = {
    "tokenized_data": inputs,           # í† í°í™”ëœ ì…ë ¥
    "ego_history_xyz": data["ego_history_xyz"],  # ê³¼ê±° ìœ„ì¹˜ ì´ë ¥
    "ego_history_rot": data["ego_history_rot"],  # ê³¼ê±° íšŒì „(ë°©í–¥) ì´ë ¥
}
model_inputs = helper.to_device(model_inputs, "cuda")
```

#### ë°ì´í„° êµ¬ì„±

| í‚¤ | ì„¤ëª… |
|----|------|
| `image_frames` | ì¹´ë©”ë¼ ì´ë¯¸ì§€ë“¤ (ì „ë°©, ì¸¡ë©´ ë“± ë‹¤ì¤‘ ì¹´ë©”ë¼) |
| `ego_history_xyz` | ì°¨ëŸ‰ì˜ ê³¼ê±° ìœ„ì¹˜ (x, y, z ì¢Œí‘œ) |
| `ego_history_rot` | ì°¨ëŸ‰ì˜ ê³¼ê±° ë°©í–¥ (íšŒì „ í–‰ë ¬) |
| `ego_future_xyz` | ì‹¤ì œ ë¯¸ë˜ ê²½ë¡œ (Ground Truth, í‰ê°€ìš©) |

---

### 4. ëª¨ë¸ ì¶”ë¡  (í•µì‹¬)

```python
torch.cuda.manual_seed_all(42)  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ì„¤ì •

with torch.autocast("cuda", dtype=torch.bfloat16):
    pred_xyz, pred_rot, extra = model.sample_trajectories_from_data_with_vlm_rollout(
        data=copy.deepcopy(model_inputs),
        top_p=0.98,              # ìƒ˜í”Œë§ ë‹¤ì–‘ì„± (nucleus sampling)
        temperature=0.6,         # ì¶œë ¥ ëœë¤ì„± ì¡°ì ˆ (ë‚®ì„ìˆ˜ë¡ ê²°ì •ì )
        num_traj_samples=1,      # ìƒì„±í•  ê²½ë¡œ ìˆ˜
        max_generation_length=256,  # ìµœëŒ€ ìƒì„± í† í° ìˆ˜
        return_extra=True,       # ì¶”ê°€ ì •ë³´(CoC) ë°˜í™˜
    )

# Chain-of-Causation ì¶œë ¥
print("Chain-of-Causation (per trajectory):\n", extra["cot"][0])
```

#### ì¶”ë¡  íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
|---------|-----|------|
| `top_p` | 0.98 | Nucleus sampling - ìƒìœ„ 98% í™•ë¥  í† í°ì—ì„œ ìƒ˜í”Œë§ |
| `temperature` | 0.6 | ë‚®ì„ìˆ˜ë¡ ê²°ì •ì , ë†’ì„ìˆ˜ë¡ ë‹¤ì–‘í•œ ì¶œë ¥ |
| `num_traj_samples` | 1 | ìƒì„±í•  ê²½ë¡œ ê°œìˆ˜ (GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ) |
| `max_generation_length` | 256 | ìµœëŒ€ ìƒì„± í† í° ìˆ˜ |

#### ì¶œë ¥ ë³€ìˆ˜

| ë³€ìˆ˜ | í˜•íƒœ | ì„¤ëª… |
|------|------|------|
| `pred_xyz` | `[batch, traj_sets, num_samples, time_steps, 3]` | ì˜ˆì¸¡ëœ ë¯¸ë˜ ê²½ë¡œ (x, y, z ì¢Œí‘œ) |
| `pred_rot` | `[batch, traj_sets, num_samples, time_steps, 3, 3]` | ì˜ˆì¸¡ëœ ë¯¸ë˜ ë°©í–¥ (íšŒì „ í–‰ë ¬) |
| `extra["cot"]` | `List[List[str]]` | Chain-of-Causation - ì£¼í–‰ ì´ìœ  ì„¤ëª… |

#### Chain-of-Causation ì˜ˆì‹œ

```
"Nudge to the left to increase clearance from the construction cones encroaching into the lane"
(ê³µì‚¬ ì½˜ì´ ì°¨ì„ ì„ ì¹¨ë²”í•˜ê³  ìˆì–´ì„œ ì™¼ìª½ìœ¼ë¡œ ì‚´ì§ ì´ë™)
```

---

### 5. ì…ë ¥ ì´ë¯¸ì§€ ì‹œê°í™”

```python
mp.show_images(
    data["image_frames"].flatten(0, 1).permute(0, 2, 3, 1), 
    columns=4, 
    width=200
)
```

ì°¨ëŸ‰ì— ì¥ì°©ëœ **ë‹¤ì¤‘ ì¹´ë©”ë¼ ì´ë¯¸ì§€**ë¥¼ ê·¸ë¦¬ë“œ í˜•íƒœë¡œ í‘œì‹œí•©ë‹ˆë‹¤ (ì „ë°©, ì¢Œì¸¡, ìš°ì¸¡ ë“±).

---

### 6. ê²½ë¡œ ì‹œê°í™”

```python
import matplotlib.pyplot as plt

def rotate_90cc(xy):
    """ì¢Œí‘œë¥¼ 90ë„ ë°˜ì‹œê³„ ë°©í–¥ìœ¼ë¡œ íšŒì „ (ì‹œê°í™”ìš©)"""
    return np.stack([-xy[1], xy[0]], axis=0)

# ì˜ˆì¸¡ ê²½ë¡œ í”Œë¡¯ (íŒŒë€ìƒ‰)
for i in range(pred_xyz.shape[2]):
    pred_xy = pred_xyz.cpu()[0, 0, i, :, :2].T.numpy()
    pred_xy_rot = rotate_90cc(pred_xy)
    plt.plot(*pred_xy_rot, "o-", label=f"Predicted Trajectory #{i + 1}")

# ì‹¤ì œ ê²½ë¡œ í”Œë¡¯ (ë¹¨ê°„ìƒ‰)
gt_xy = data["ego_future_xyz"].cpu()[0, 0, :, :2].T.numpy()
gt_xy_rot = rotate_90cc(gt_xy)
plt.plot(*gt_xy_rot, "r-", label="Ground Truth Trajectory")

plt.ylabel("y coordinate (meters)")
plt.xlabel("x coordinate (meters)")
plt.legend(loc="best")
plt.axis("equal")
```

#### ê·¸ë˜í”„ ì„¤ëª…

| ìš”ì†Œ | ìƒ‰ìƒ | ì„¤ëª… |
|------|------|------|
| ì˜ˆì¸¡ ê²½ë¡œ | ğŸ”µ íŒŒë€ìƒ‰ ì ì„  | ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ë¯¸ë˜ ì£¼í–‰ ê²½ë¡œ |
| ì‹¤ì œ ê²½ë¡œ | ğŸ”´ ë¹¨ê°„ìƒ‰ ì‹¤ì„  | Ground Truth (ì‹¤ì œ ì£¼í–‰ ê²½ë¡œ) |

---

### 7. ì •í™•ë„ í‰ê°€ (minADE)

```python
pred_xy = pred_xyz.cpu().numpy()[0, 0, :, :, :2].transpose(0, 2, 1)
diff = np.linalg.norm(pred_xy - gt_xy[None, ...], axis=1).mean(-1)
print("minADE:", diff.min(), "meters")
```

#### minADE (minimum Average Displacement Error)

- **ì •ì˜**: ì˜ˆì¸¡ ê²½ë¡œì™€ ì‹¤ì œ ê²½ë¡œ ì‚¬ì´ì˜ í‰ê·  ê±°ë¦¬ ì˜¤ì°¨
- **ê³„ì‚°**: ê° ì‹œê°„ ìŠ¤í…ì—ì„œì˜ ìœ í´ë¦¬ë“œ ê±°ë¦¬ì˜ í‰ê· 
- **ê²°ê³¼**: `0.75916 meters` â†’ ì•½ **76cm ì˜¤ì°¨**

```
minADE = (1/T) Ã— Î£ ||pred_xy[t] - gt_xy[t]||â‚‚
```

---

## í•µì‹¬ ê°œë…: VLA (Vision-Language-Action) ëª¨ë¸

Alpamayo-R1ì€ **VLA ëª¨ë¸**ë¡œ, ì„¸ ê°€ì§€ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í†µí•©í•©ë‹ˆë‹¤:

| ëª¨ë‹¬ë¦¬í‹° | ì—­í•  | ì˜ˆì‹œ |
|---------|------|------|
| **Vision** | ì¹´ë©”ë¼ ì´ë¯¸ì§€ ë¶„ì„ | ì „ë°© ì¹´ë©”ë¼, ì¸¡ë©´ ì¹´ë©”ë¼ ì˜ìƒ |
| **Language** | ìƒí™© ì´í•´ ë° ì´ìœ  ì„¤ëª… | "ê³µì‚¬ ì½˜ì„ í”¼í•´ ì™¼ìª½ìœ¼ë¡œ ì´ë™" |
| **Action** | ì£¼í–‰ ê²½ë¡œ ìƒì„± | (x, y, z) ì¢Œí‘œ ì‹œí€€ìŠ¤ |

### ê¸°ì¡´ ììœ¨ì£¼í–‰ vs VLA ê¸°ë°˜ ììœ¨ì£¼í–‰

| êµ¬ë¶„ | ê¸°ì¡´ ë°©ì‹ | VLA ë°©ì‹ (Alpamayo-R1) |
|------|----------|------------------------|
| ì˜ì‚¬ê²°ì • | Rule-based / End-to-end | ì–¸ì–´ ê¸°ë°˜ ì¶”ë¡  |
| ì„¤ëª… ê°€ëŠ¥ì„± | ë‚®ìŒ (ë¸”ë™ë°•ìŠ¤) | ë†’ìŒ (CoC ì œê³µ) |
| ì¼ë°˜í™” | ì œí•œì  | ë†’ì€ ì¼ë°˜í™” ëŠ¥ë ¥ |

---

## ì‹¤í–‰ í™˜ê²½

| í•­ëª© | ìš”êµ¬ì‚¬í•­ |
|------|---------|
| Python | 3.12+ |
| GPU | 24GB VRAM ê¶Œì¥ (RTX 4090, RTX 5090 ë“±) |
| CUDA | 12.4+ |
| ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ | torch, transformers, einops, hydra-core |

---

## ì°¸ê³  ìë£Œ

- [Alpamayo GitHub](https://github.com/NVlabs/alpamayo)
- [Alpamayo-R1-10B (HuggingFace)](https://huggingface.co/nvidia/Alpamayo-R1-10B)
- [PhysicalAI-AV Dataset (HuggingFace)](https://huggingface.co/datasets/nvidia/PhysicalAI-Autonomous-Vehicles)

---

*ì‘ì„±ì¼: 2026-01-27*
